{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgR9yKPsOrLh",
        "outputId": "392a7a38-0119-4151-8ad7-b5ebae2453f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.12-py3-none-any.whl (809 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/809.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/809.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/809.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.28 (from langchain)\n",
            "  Downloading langchain_community-0.0.28-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.31 (from langchain)\n",
            "  Downloading langchain_core-0.1.32-py3-none-any.whl (260 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.29-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.9/70.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (3.7.1)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.31->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.12 langchain-community-0.0.28 langchain-core-0.1.32 langchain-text-splitters-0.0.1 langsmith-0.1.29 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 packaging-23.2 typing-inspect-0.9.0\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, faiss-cpu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed faiss-cpu-1.8.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 sentence-transformers-2.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install sentence-transformers faiss-cpu\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('/content/conversation_history.json', 'r') as file:\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "id": "mV57zIVyaxOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = [message['text'] for message in data]"
      ],
      "metadata": {
        "id": "dqXO4pLBc6bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "id": "5Th0CKvEO2Zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "596d6654-94b9-400f-ff7d-9e8dc23243d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<@U06PS204W0L> has joined the channel',\n",
              " '<!channel> please share your views about the product we are working on.',\n",
              " 'I curated several use cases for our Slack Bot.\\nNow I shall create the dataset for the same.',\n",
              " 'Everyone, please update your work.',\n",
              " 'Hi Team,\\n\\nToday me and @Ganesh sir worked on the architecture of Slack API.\\nNow, I am building ORM using Django.',\n",
              " '<@U06PL3Y8DEK> has joined the channel',\n",
              " 'Hey everyone,\\nKindly share the updates please.',\n",
              " 'Okay',\n",
              " 'Sure Hitesh ',\n",
              " \"Hello Team,\\n\\nAs I already mentioned we are using this channel for our data creation.\\nSo, please try to use the same channel for reporting the updates or if you have any queries or any findings just try to push that on the same channel.\\nTry to replace WhatsApp or individual DM's to our slack channel so that we populate some data here to work on.\",\n",
              " 'Hello Team,\\n\\nCan we have a short meeting after we finish this meeting?',\n",
              " '<@U06QF6DJPTJ> has joined the channel',\n",
              " 'Hello everyone,\\n\\nWe are using this channel to generate our conversational data to work on.\\nSo I would like everyone to come here and have chats on their task, any doubts.\\nUse this channel instead of using WhatsApp.\\n\\nThank you!',\n",
              " '<@U06Q4LMR03B> has joined the channel',\n",
              " '<@U06PR7VUF1R> has joined the channel',\n",
              " '<@U06Q3THS0P3> has joined the channel',\n",
              " '<@U06PGS6FSUW> has joined the channel']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXNYRbq3dtJg",
        "outputId": "810c16dd-4bbf-4a91-f944-982cac93caf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'subtype': 'channel_join',\n",
              "  'user': 'U06PS204W0L',\n",
              "  'text': '<@U06PS204W0L> has joined the channel',\n",
              "  'inviter': 'U06PL3Y8DEK',\n",
              "  'type': 'message',\n",
              "  'ts': '1710827776.077939'},\n",
              " {'user': 'U06QF6DJPTJ',\n",
              "  'type': 'message',\n",
              "  'ts': '1710772641.448379',\n",
              "  'client_msg_id': '4c5f06f5-a311-4b89-9d32-4e8d833bac36',\n",
              "  'text': '<!channel> please share your views about the product we are working on.',\n",
              "  'team': 'T06Q25C79H7',\n",
              "  'blocks': [{'type': 'rich_text',\n",
              "    'block_id': 'HPwjY',\n",
              "    'elements': [{'type': 'rich_text_section',\n",
              "      'elements': [{'type': 'broadcast', 'range': 'channel'},\n",
              "       {'type': 'text',\n",
              "        'text': ' please share your views about the product we are working on.'}]}]}]},\n",
              " {'user': 'U06QF6DJPTJ',\n",
              "  'type': 'message',\n",
              "  'ts': '1710757181.390189',\n",
              "  'client_msg_id': 'e2ee4aa3-6c75-4f6c-a609-84b46406444c',\n",
              "  'text': 'I curated several use cases for our Slack Bot.\\nNow I shall create the dataset for the same.',\n",
              "  'team': 'T06Q25C79H7',\n",
              "  'blocks': [{'type': 'rich_text',\n",
              "    'block_id': 'eSwai',\n",
              "    'elements': [{'type': 'rich_text_section',\n",
              "      'elements': [{'type': 'text',\n",
              "        'text': 'I curated several use cases for our Slack Bot.\\nNow I shall create the dataset for the same.'}]}]}]},\n",
              " {'user': 'U06PGS6FSUW',\n",
              "  'type': 'message',\n",
              "  'ts': '1710755842.490189',\n",
              "  'client_msg_id': 'a52fad34-3f62-4832-8616-c5ff6bf45baf',\n",
              "  'text': 'Everyone, please update your work.',\n",
              "  'team': 'T06Q25C79H7',\n",
              "  'blocks': [{'type': 'rich_text',\n",
              "    'block_id': 'thHBj',\n",
              "    'elements': [{'type': 'rich_text_section',\n",
              "      'elements': [{'type': 'text',\n",
              "        'text': 'Everyone, please update your work.'}]}]}]},\n",
              " {'user': 'U06PGS6FSUW',\n",
              "  'type': 'message',\n",
              "  'ts': '1710755810.819219',\n",
              "  'client_msg_id': '102ca4a3-70e0-4d71-b0fb-2962c02b6726',\n",
              "  'text': 'Hi Team,\\n\\nToday me and @Ganesh sir worked on the architecture of Slack API.\\nNow, I am building ORM using Django.',\n",
              "  'team': 'T06Q25C79H7',\n",
              "  'blocks': [{'type': 'rich_text',\n",
              "    'block_id': '/P/c8',\n",
              "    'elements': [{'type': 'rich_text_section',\n",
              "      'elements': [{'type': 'text',\n",
              "        'text': 'Hi Team,\\n\\nToday me and @Ganesh sir worked on the architecture of Slack API.\\nNow, I am building ORM using Django.'}]}]}]},\n",
              " {'subtype': 'channel_join',\n",
              "  'user': 'U06PL3Y8DEK',\n",
              "  'text': '<@U06PL3Y8DEK> has joined the channel',\n",
              "  'type': 'message',\n",
              "  'ts': '1710755621.143079'},\n",
              " {'user': 'U06QF6DJPTJ',\n",
              "  'type': 'message',\n",
              "  'ts': '1710742566.963689',\n",
              "  'client_msg_id': 'b56e18fe-beea-4350-a30f-b089f02df9ab',\n",
              "  'text': 'Hey everyone,\\nKindly share the updates please.',\n",
              "  'team': 'T06Q25C79H7',\n",
              "  'blocks': [{'type': 'rich_text',\n",
              "    'block_id': 'ERkl3',\n",
              "    'elements': [{'type': 'rich_text_section',\n",
              "      'elements': [{'type': 'text',\n",
              "        'text': 'Hey everyone,\\nKindly share the updates please.'}]}]}]},\n",
              " {'user': 'U06QF6DJPTJ',\n",
              "  'type': 'message',\n",
              "  'ts': '1710567621.668099',\n",
              "  'client_msg_id': '2bb94ede-f20f-4ace-8999-f3b730b29419',\n",
              "  'text': 'Okay',\n",
              "  'team': 'T06Q25C79H7',\n",
              "  'blocks': [{'type': 'rich_text',\n",
              "    'block_id': 'HMYXF',\n",
              "    'elements': [{'type': 'rich_text_section',\n",
              "      'elements': [{'type': 'text', 'text': 'Okay'}]}]}]},\n",
              " {'user': 'U06Q3THS0P3',\n",
              "  'type': 'message',\n",
              "  'ts': '1710567104.137569',\n",
              "  'client_msg_id': 'E8858228-3DD0-4715-9BF7-6EFBE7A69D63',\n",
              "  'text': 'Sure Hitesh ',\n",
              "  'team': 'T06Q25C79H7',\n",
              "  'blocks': [{'type': 'rich_text',\n",
              "    'block_id': 'cOo6I',\n",
              "    'elements': [{'type': 'rich_text_section',\n",
              "      'elements': [{'type': 'text', 'text': 'Sure Hitesh '}]}]}]},\n",
              " {'user': 'U06PGS6FSUW',\n",
              "  'type': 'message',\n",
              "  'ts': '1710567082.400129',\n",
              "  'client_msg_id': 'fbf98276-a5b3-4578-9ff7-ad2fcb7e117c',\n",
              "  'text': \"Hello Team,\\n\\nAs I already mentioned we are using this channel for our data creation.\\nSo, please try to use the same channel for reporting the updates or if you have any queries or any findings just try to push that on the same channel.\\nTry to replace WhatsApp or individual DM's to our slack channel so that we populate some data here to work on.\",\n",
              "  'team': 'T06Q25C79H7',\n",
              "  'blocks': [{'type': 'rich_text',\n",
              "    'block_id': '+o6JI',\n",
              "    'elements': [{'type': 'rich_text_section',\n",
              "      'elements': [{'type': 'text',\n",
              "        'text': \"Hello Team,\\n\\nAs I already mentioned we are using this channel for our data creation.\\nSo, please try to use the same channel for reporting the updates or if you have any queries or any findings just try to push that on the same channel.\\nTry to replace WhatsApp or individual DM's to our slack channel so that we populate some data here to work on.\"}]}]}]},\n",
              " {'user': 'U06PGS6FSUW',\n",
              "  'type': 'message',\n",
              "  'ts': '1710563238.306449',\n",
              "  'client_msg_id': '617050da-502a-4935-8136-f8ddbdffe616',\n",
              "  'text': 'Hello Team,\\n\\nCan we have a short meeting after we finish this meeting?',\n",
              "  'team': 'T06Q25C79H7',\n",
              "  'blocks': [{'type': 'rich_text',\n",
              "    'block_id': 'WgkDs',\n",
              "    'elements': [{'type': 'rich_text_section',\n",
              "      'elements': [{'type': 'text',\n",
              "        'text': 'Hello Team,\\n\\nCan we have a short meeting after we finish this meeting?'}]}]}]},\n",
              " {'subtype': 'channel_join',\n",
              "  'user': 'U06QF6DJPTJ',\n",
              "  'text': '<@U06QF6DJPTJ> has joined the channel',\n",
              "  'type': 'message',\n",
              "  'ts': '1710514896.203279'},\n",
              " {'user': 'U06PGS6FSUW',\n",
              "  'type': 'message',\n",
              "  'ts': '1710513759.556259',\n",
              "  'client_msg_id': '58c6e002-4074-46ec-b82a-d912ec2ab939',\n",
              "  'text': 'Hello everyone,\\n\\nWe are using this channel to generate our conversational data to work on.\\nSo I would like everyone to come here and have chats on their task, any doubts.\\nUse this channel instead of using WhatsApp.\\n\\nThank you!',\n",
              "  'team': 'T06Q25C79H7',\n",
              "  'blocks': [{'type': 'rich_text',\n",
              "    'block_id': 'd3cav',\n",
              "    'elements': [{'type': 'rich_text_section',\n",
              "      'elements': [{'type': 'text',\n",
              "        'text': 'Hello everyone,\\n\\nWe are using this channel to generate our conversational data to work on.\\nSo I would like everyone to come here and have chats on their task, any doubts.\\nUse this channel instead of using WhatsApp.\\n\\nThank you!'}]}]}]},\n",
              " {'subtype': 'channel_join',\n",
              "  'user': 'U06Q4LMR03B',\n",
              "  'text': '<@U06Q4LMR03B> has joined the channel',\n",
              "  'type': 'message',\n",
              "  'ts': '1710511717.594979'},\n",
              " {'subtype': 'channel_join',\n",
              "  'user': 'U06PR7VUF1R',\n",
              "  'text': '<@U06PR7VUF1R> has joined the channel',\n",
              "  'type': 'message',\n",
              "  'ts': '1710505095.457159'},\n",
              " {'subtype': 'channel_join',\n",
              "  'user': 'U06Q3THS0P3',\n",
              "  'text': '<@U06Q3THS0P3> has joined the channel',\n",
              "  'type': 'message',\n",
              "  'ts': '1710503913.036029'},\n",
              " {'subtype': 'channel_join',\n",
              "  'user': 'U06PGS6FSUW',\n",
              "  'text': '<@U06PGS6FSUW> has joined the channel',\n",
              "  'type': 'message',\n",
              "  'ts': '1710479820.411779'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
        "for message in text:\n",
        "    chunks = text_splitter.split_text(message)\n",
        "    texts.extend(chunks)\n"
      ],
      "metadata": {
        "id": "gfw9Kev1O6UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxEpsPLL5b5z",
        "outputId": "753a81e8-343d-47b2-8b33-f162d903c33f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<@U06PS204W0L> has joined the channel', '<!channel> please share your views about the product we are working on.', 'I curated several use cases for our Slack Bot.\\nNow I shall create the dataset for the same.', 'Everyone, please update your work.', 'Hi Team,\\n\\nToday me and @Ganesh sir worked on the architecture of Slack API.\\nNow, I am building ORM using Django.', '<@U06PL3Y8DEK> has joined the channel', 'Hey everyone,\\nKindly share the updates please.', 'Okay', 'Sure Hitesh', 'Hello Team,', \"As I already mentioned we are using this channel for our data creation.\\nSo, please try to use the same channel for reporting the updates or if you have any queries or any findings just try to push that on the same channel.\\nTry to replace WhatsApp or individual DM's to our slack channel so that we populate some data here to work on.\", 'Hello Team,\\n\\nCan we have a short meeting after we finish this meeting?', '<@U06QF6DJPTJ> has joined the channel', 'Hello everyone,', 'We are using this channel to generate our conversational data to work on.\\nSo I would like everyone to come here and have chats on their task, any doubts.\\nUse this channel instead of using WhatsApp.', 'Thank you!', '<@U06Q4LMR03B> has joined the channel', '<@U06PR7VUF1R> has joined the channel', '<@U06Q3THS0P3> has joined the channel', '<@U06PGS6FSUW> has joined the channel']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"thenlper/gte-base\"\n",
        "model = SentenceTransformer(model_name)\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "embeddings = model.encode(texts)\n",
        "\n",
        "embeddings /= np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "\n",
        "##Create a FAISS index\n",
        "\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(embeddings)\n"
      ],
      "metadata": {
        "id": "ZkeLbUpYO9JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nEvaluating FAISS index...\")\n",
        "query = \"Who worked on the architecture of the Slack API?\"\n",
        "query_embedding = model.encode([query])\n",
        "scores, indices = index.search(query_embedding, k=5)\n",
        "print(f\"Top 5 results for '{query}':\")\n",
        "for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
        "\n",
        "    # Calculate cosine similarity from Euclidean distance\n",
        "    cosine_similarity = 1.0 - (score / (2 * embeddings.shape[1])) ** 0.5\n",
        "\n",
        "    print(f\"Result {i+1} (Similarity: {cosine_similarity:.4f}):\")\n",
        "    print(f\"Content: {texts[idx][:200]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6gIiy39Pthh",
        "outputId": "62c8a15f-6577-41c9-8694-67234a34d834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating FAISS index...\n",
            "Top 5 results for 'Who worked on the architecture of the Slack API?':\n",
            "Result 1 (Similarity: 0.9903):\n",
            "Content: Hi Team,\n",
            "\n",
            "Today me and @Ganesh sir worked on the architecture of Slack API.\n",
            "Now, I am building ORM using Django....\n",
            "Result 2 (Similarity: 0.9876):\n",
            "Content: I curated several use cases for our Slack Bot.\n",
            "Now I shall create the dataset for the same....\n",
            "Result 3 (Similarity: 0.9848):\n",
            "Content: As I already mentioned we are using this channel for our data creation.\n",
            "So, please try to use the same channel for reporting the updates or if you have any queries or any findings just try to push tha...\n",
            "Result 4 (Similarity: 0.9835):\n",
            "Content: <@U06Q3THS0P3> has joined the channel...\n",
            "Result 5 (Similarity: 0.9835):\n",
            "Content: <@U06PS204W0L> has joined the channel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\n",
        "    \"Who worked on the architecture of the Slack API?\",\n",
        "    \"We are using this channel to generate \"\n",
        "]\n",
        "\n",
        "# Perform searches for each query\n",
        "for query in queries:\n",
        "    query_embedding = model.encode([query])\n",
        "    scores, indices = index.search(query_embedding, k=2)\n",
        "\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
        "\n",
        "        # Calculate cosine similarity from Euclidean distance\n",
        "        cosine_similarity = 1.0 - (score / (2 * embeddings.shape[1])) ** 0.5\n",
        "\n",
        "        print(f\" Result {i+1} (Similarity: {cosine_similarity:.4f}):\")\n",
        "        print(f\" Content: {texts[idx]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOzk4XQ4P4wX",
        "outputId": "2757f6c4-f195-49b8-c7dd-a083358f3c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: Who worked on the architecture of the Slack API?\n",
            " Result 1 (Similarity: 0.9903):\n",
            " Content: Hi Team,\n",
            "\n",
            "Today me and @Ganesh sir worked on the architecture of Slack API.\n",
            "Now, I am building ORM using Django....\n",
            " Result 2 (Similarity: 0.9876):\n",
            " Content: I curated several use cases for our Slack Bot.\n",
            "Now I shall create the dataset for the same....\n",
            "\n",
            "Query: We are using this channel to generate \n",
            " Result 1 (Similarity: 0.9881):\n",
            " Content: We are using this channel to generate our conversational data to work on.\n",
            "So I would like everyone to come here and have chats on their task, any doubts.\n",
            "Use this channel instead of using WhatsApp....\n",
            " Result 2 (Similarity: 0.9867):\n",
            " Content: As I already mentioned we are using this channel for our data creation.\n",
            "So, please try to use the same channel for reporting the updates or if you have any queries or any findings just try to push that on the same channel.\n",
            "Try to replace WhatsApp or individual DM's to our slack channel so that we populate some data here to work on....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance metrics\n",
        "import time\n",
        "total_query_response_time = 0\n",
        "\n",
        "for query in queries:\n",
        "    start_time = time.time()\n",
        "    query_embedding = model.encode([query])\n",
        "    scores, indices = index.search(query_embedding, k=3)\n",
        "    end_time = time.time()\n",
        "\n",
        "    query_response_time = end_time - start_time\n",
        "    total_query_response_time += query_response_time\n",
        "\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    print(f\"Query Response Time: {query_response_time:.4f} seconds\")\n",
        "\n",
        "\n",
        "# Average performance metrics\n",
        "average_query_response_time = total_query_response_time / len(queries)\n",
        "\n",
        "\n",
        "print(f\"\\nAverage Query Response Time: {average_query_response_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt_U_ppGP8GO",
        "outputId": "ed8a8d9f-e10d-43f9-ba2a-8b2e33b463c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: Who worked on the architecture of the Slack API?\n",
            "Query Response Time: 0.1010 seconds\n",
            "\n",
            "Query: We are using this channel to generate \n",
            "Query Response Time: 0.0836 seconds\n",
            "\n",
            "Average Query Response Time: 0.0923 seconds\n"
          ]
        }
      ]
    }
  ]
}